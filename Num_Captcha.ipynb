{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Num_Captcha.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYEVGk4jJl9rP7hfSCITJy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlokendra/Navia_life_care_Assignment1/blob/main/Num_Captcha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8voL-eqz5H6"
      },
      "source": [
        "# **Libraries required**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxWtlAAAYRMD"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import random, randint, choices\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3s08MDR0IQ1"
      },
      "source": [
        "# **Data Loading And Pre-processing**`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bp_fhLT61iE"
      },
      "source": [
        "def load_data(path, test_split=0.1):\n",
        "    print ('loading dataset...')\n",
        "    y_train = []\n",
        "    y_test = []\n",
        "    x_train = []\n",
        "    x_test = []\n",
        "\n",
        "    # r=root, d=directories, f = files\n",
        "    counter = 0\n",
        "    for r, d, f in os.walk(path):\n",
        "        for fl in f[:100]:\n",
        "            if '.png' in fl:\n",
        "                flr = fl.split('_')[0]\n",
        "                counter += 1\n",
        "                label = np.zeros((NUM_OF_LETTERS, 10))\n",
        "                for i in range(NUM_OF_LETTERS):\n",
        "                    label[i, int(flr[i])] = 1\n",
        "\n",
        "                img = cv2.imread(os.path.join(r, fl))\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                img = cv2.resize(img, (int(135/2), int(50/2)), interpolation=cv2.INTER_AREA)\n",
        "                img = np.reshape(img, (img.shape[0], img.shape[1], 1))\n",
        "\n",
        "                if random() < test_split:\n",
        "                    y_test.append(label)\n",
        "                    x_test.append(img)\n",
        "                else:\n",
        "                    y_train.append(label)\n",
        "                    x_train.append(img)\n",
        "\n",
        "\n",
        "    print('dataset size:', counter, '(train=%d, test=%d)' % (len(y_train), len(y_test)))\n",
        "    return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrpJ2sXU9gpx",
        "outputId": "3fa7ddc6-470d-4d16-e91c-912b9b1c39de"
      },
      "source": [
        "NUM_OF_LETTERS=5\n",
        "x_train, y_train, x_test, y_test = load_data('./electoral-tagged')\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading dataset...\n",
            "dataset size: 938 (train=858, test=80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkTzoLtU9uGT",
        "outputId": "85e57080-ee7c-4fcd-8e73-3711382088ce"
      },
      "source": [
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(858, 25, 67, 1)\n",
            "(858, 5, 10)\n",
            "(80, 25, 67, 1)\n",
            "(80, 5, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL8VqlJ30u79"
      },
      "source": [
        "# **MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5D3WK9H_gbW",
        "outputId": "478d5d04-0e48-482a-8a29-7d6ffa5a1ded"
      },
      "source": [
        "input_layer = Input((25, 67, 1))\n",
        "x = Conv2D(filters=16, kernel_size=(5, 5), padding='same', activation='relu')(input_layer)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "x = Conv2D(filters=32, kernel_size=(5, 5), padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "x = Conv2D(filters=64, kernel_size=(5, 5), padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "x = Conv2D(filters=128, kernel_size=(5, 5), padding='same', activation='relu')(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "x = Dropout(0.3)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "out = [Dense(10, name='digit%d' % i, activation='softmax')(x) for i in range(NUM_OF_LETTERS)]\n",
        "model = Model(inputs=input_layer, outputs=out)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 25, 67, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 67, 16)   416         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 12, 33, 16)   0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 12, 33, 32)   12832       max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 6, 16, 32)    0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 6, 16, 64)    51264       max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling2D) (None, 3, 8, 64)     0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 3, 8, 128)    204928      max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 1, 4, 128)    0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 1, 4, 128)    0           max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 512)          0           dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 512)          262656      flatten_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 512)          0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "digit0 (Dense)                  (None, 10)           5130        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "digit1 (Dense)                  (None, 10)           5130        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "digit2 (Dense)                  (None, 10)           5130        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "digit3 (Dense)                  (None, 10)           5130        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "digit4 (Dense)                  (None, 10)           5130        dropout_11[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 557,746\n",
            "Trainable params: 557,746\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28RARUMl_yHZ"
      },
      "source": [
        "s_train = []\n",
        "s_test = []\n",
        "for i in range(NUM_OF_LETTERS):\n",
        "    s_train.append(y_train[:, i, :])\n",
        "    s_test.append(y_test[:, i, :])"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpSd5L8CAIWJ",
        "outputId": "0301b358-b344-477a-9c11-d2c94a6e0248"
      },
      "source": [
        "# train in multiple steps \n",
        "history = model.fit(x_train, s_train,\n",
        "                    batch_size=32,\n",
        "                    epochs=120,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, s_test)\n",
        "                   )"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 0.0991 - digit0_loss: 0.0169 - digit1_loss: 0.0207 - digit2_loss: 0.0227 - digit3_loss: 0.0240 - digit4_loss: 0.0147 - digit0_accuracy: 0.9895 - digit1_accuracy: 0.9848 - digit2_accuracy: 0.9802 - digit3_accuracy: 0.9767 - digit4_accuracy: 0.9895 - val_loss: 0.7136 - val_digit0_loss: 0.0588 - val_digit1_loss: 0.1349 - val_digit2_loss: 0.2081 - val_digit3_loss: 0.1850 - val_digit4_loss: 0.1268 - val_digit0_accuracy: 0.9125 - val_digit1_accuracy: 0.7750 - val_digit2_accuracy: 0.6625 - val_digit3_accuracy: 0.7000 - val_digit4_accuracy: 0.8375\n",
            "Epoch 2/20\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 0.0931 - digit0_loss: 0.0123 - digit1_loss: 0.0219 - digit2_loss: 0.0219 - digit3_loss: 0.0215 - digit4_loss: 0.0155 - digit0_accuracy: 0.9860 - digit1_accuracy: 0.9790 - digit2_accuracy: 0.9814 - digit3_accuracy: 0.9802 - digit4_accuracy: 0.9918 - val_loss: 0.7663 - val_digit0_loss: 0.0546 - val_digit1_loss: 0.1385 - val_digit2_loss: 0.2255 - val_digit3_loss: 0.2250 - val_digit4_loss: 0.1226 - val_digit0_accuracy: 0.9500 - val_digit1_accuracy: 0.7875 - val_digit2_accuracy: 0.6875 - val_digit3_accuracy: 0.7000 - val_digit4_accuracy: 0.8375\n",
            "Epoch 3/20\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 0.0864 - digit0_loss: 0.0148 - digit1_loss: 0.0180 - digit2_loss: 0.0184 - digit3_loss: 0.0187 - digit4_loss: 0.0165 - digit0_accuracy: 0.9907 - digit1_accuracy: 0.9837 - digit2_accuracy: 0.9872 - digit3_accuracy: 0.9895 - digit4_accuracy: 0.9883 - val_loss: 0.6818 - val_digit0_loss: 0.0410 - val_digit1_loss: 0.1465 - val_digit2_loss: 0.2061 - val_digit3_loss: 0.1756 - val_digit4_loss: 0.1127 - val_digit0_accuracy: 0.9125 - val_digit1_accuracy: 0.7625 - val_digit2_accuracy: 0.6625 - val_digit3_accuracy: 0.7125 - val_digit4_accuracy: 0.8625\n",
            "Epoch 4/20\n",
            "27/27 [==============================] - 4s 144ms/step - loss: 0.0862 - digit0_loss: 0.0124 - digit1_loss: 0.0171 - digit2_loss: 0.0202 - digit3_loss: 0.0218 - digit4_loss: 0.0147 - digit0_accuracy: 0.9883 - digit1_accuracy: 0.9848 - digit2_accuracy: 0.9744 - digit3_accuracy: 0.9825 - digit4_accuracy: 0.9848 - val_loss: 0.7291 - val_digit0_loss: 0.0396 - val_digit1_loss: 0.1564 - val_digit2_loss: 0.2085 - val_digit3_loss: 0.2025 - val_digit4_loss: 0.1221 - val_digit0_accuracy: 0.9375 - val_digit1_accuracy: 0.7625 - val_digit2_accuracy: 0.7000 - val_digit3_accuracy: 0.7000 - val_digit4_accuracy: 0.8625\n",
            "Epoch 5/20\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 0.0825 - digit0_loss: 0.0106 - digit1_loss: 0.0181 - digit2_loss: 0.0198 - digit3_loss: 0.0189 - digit4_loss: 0.0151 - digit0_accuracy: 0.9930 - digit1_accuracy: 0.9895 - digit2_accuracy: 0.9837 - digit3_accuracy: 0.9872 - digit4_accuracy: 0.9883 - val_loss: 0.8024 - val_digit0_loss: 0.0593 - val_digit1_loss: 0.1419 - val_digit2_loss: 0.2410 - val_digit3_loss: 0.2261 - val_digit4_loss: 0.1341 - val_digit0_accuracy: 0.9250 - val_digit1_accuracy: 0.7750 - val_digit2_accuracy: 0.6625 - val_digit3_accuracy: 0.6500 - val_digit4_accuracy: 0.8250\n",
            "Epoch 6/20\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0822 - digit0_loss: 0.0108 - digit1_loss: 0.0163 - digit2_loss: 0.0198 - digit3_loss: 0.0191 - digit4_loss: 0.0162 - digit0_accuracy: 0.9918 - digit1_accuracy: 0.9872 - digit2_accuracy: 0.9825 - digit3_accuracy: 0.9837 - digit4_accuracy: 0.9895 - val_loss: 0.6783 - val_digit0_loss: 0.0404 - val_digit1_loss: 0.1420 - val_digit2_loss: 0.2058 - val_digit3_loss: 0.1988 - val_digit4_loss: 0.0913 - val_digit0_accuracy: 0.9250 - val_digit1_accuracy: 0.7125 - val_digit2_accuracy: 0.6250 - val_digit3_accuracy: 0.7000 - val_digit4_accuracy: 0.8875\n",
            "Epoch 7/20\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 0.0830 - digit0_loss: 0.0125 - digit1_loss: 0.0160 - digit2_loss: 0.0183 - digit3_loss: 0.0200 - digit4_loss: 0.0161 - digit0_accuracy: 0.9883 - digit1_accuracy: 0.9895 - digit2_accuracy: 0.9848 - digit3_accuracy: 0.9802 - digit4_accuracy: 0.9837 - val_loss: 0.6844 - val_digit0_loss: 0.0370 - val_digit1_loss: 0.1417 - val_digit2_loss: 0.2047 - val_digit3_loss: 0.1892 - val_digit4_loss: 0.1118 - val_digit0_accuracy: 0.9625 - val_digit1_accuracy: 0.7625 - val_digit2_accuracy: 0.6875 - val_digit3_accuracy: 0.6750 - val_digit4_accuracy: 0.8625\n",
            "Epoch 8/20\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 0.0822 - digit0_loss: 0.0131 - digit1_loss: 0.0170 - digit2_loss: 0.0176 - digit3_loss: 0.0182 - digit4_loss: 0.0164 - digit0_accuracy: 0.9953 - digit1_accuracy: 0.9895 - digit2_accuracy: 0.9907 - digit3_accuracy: 0.9872 - digit4_accuracy: 0.9825 - val_loss: 0.6976 - val_digit0_loss: 0.0407 - val_digit1_loss: 0.1499 - val_digit2_loss: 0.2089 - val_digit3_loss: 0.2005 - val_digit4_loss: 0.0977 - val_digit0_accuracy: 0.9250 - val_digit1_accuracy: 0.7500 - val_digit2_accuracy: 0.6500 - val_digit3_accuracy: 0.6875 - val_digit4_accuracy: 0.8750\n",
            "Epoch 9/20\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 0.0821 - digit0_loss: 0.0134 - digit1_loss: 0.0158 - digit2_loss: 0.0198 - digit3_loss: 0.0181 - digit4_loss: 0.0149 - digit0_accuracy: 0.9907 - digit1_accuracy: 0.9907 - digit2_accuracy: 0.9848 - digit3_accuracy: 0.9825 - digit4_accuracy: 0.9907 - val_loss: 0.7556 - val_digit0_loss: 0.0426 - val_digit1_loss: 0.1841 - val_digit2_loss: 0.2395 - val_digit3_loss: 0.2048 - val_digit4_loss: 0.0846 - val_digit0_accuracy: 0.9375 - val_digit1_accuracy: 0.7000 - val_digit2_accuracy: 0.6250 - val_digit3_accuracy: 0.6625 - val_digit4_accuracy: 0.9000\n",
            "Epoch 10/20\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 0.0894 - digit0_loss: 0.0124 - digit1_loss: 0.0179 - digit2_loss: 0.0214 - digit3_loss: 0.0215 - digit4_loss: 0.0161 - digit0_accuracy: 0.9918 - digit1_accuracy: 0.9860 - digit2_accuracy: 0.9802 - digit3_accuracy: 0.9790 - digit4_accuracy: 0.9907 - val_loss: 0.7006 - val_digit0_loss: 0.0419 - val_digit1_loss: 0.1588 - val_digit2_loss: 0.2074 - val_digit3_loss: 0.2006 - val_digit4_loss: 0.0919 - val_digit0_accuracy: 0.9375 - val_digit1_accuracy: 0.7000 - val_digit2_accuracy: 0.6375 - val_digit3_accuracy: 0.7000 - val_digit4_accuracy: 0.8750\n",
            "Epoch 11/20\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 0.0822 - digit0_loss: 0.0118 - digit1_loss: 0.0154 - digit2_loss: 0.0179 - digit3_loss: 0.0206 - digit4_loss: 0.0165 - digit0_accuracy: 0.9872 - digit1_accuracy: 0.9872 - digit2_accuracy: 0.9848 - digit3_accuracy: 0.9825 - digit4_accuracy: 0.9848 - val_loss: 0.7041 - val_digit0_loss: 0.0356 - val_digit1_loss: 0.1658 - val_digit2_loss: 0.2129 - val_digit3_loss: 0.1968 - val_digit4_loss: 0.0930 - val_digit0_accuracy: 0.9500 - val_digit1_accuracy: 0.6875 - val_digit2_accuracy: 0.7000 - val_digit3_accuracy: 0.6750 - val_digit4_accuracy: 0.8875\n",
            "Epoch 12/20\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0727 - digit0_loss: 0.0111 - digit1_loss: 0.0157 - digit2_loss: 0.0142 - digit3_loss: 0.0166 - digit4_loss: 0.0152 - digit0_accuracy: 0.9918 - digit1_accuracy: 0.9860 - digit2_accuracy: 0.9895 - digit3_accuracy: 0.9895 - digit4_accuracy: 0.9872 - val_loss: 0.6727 - val_digit0_loss: 0.0276 - val_digit1_loss: 0.1420 - val_digit2_loss: 0.2144 - val_digit3_loss: 0.1925 - val_digit4_loss: 0.0963 - val_digit0_accuracy: 0.9750 - val_digit1_accuracy: 0.7500 - val_digit2_accuracy: 0.6750 - val_digit3_accuracy: 0.7250 - val_digit4_accuracy: 0.8750\n",
            "Epoch 13/20\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 0.0720 - digit0_loss: 0.0091 - digit1_loss: 0.0153 - digit2_loss: 0.0142 - digit3_loss: 0.0195 - digit4_loss: 0.0139 - digit0_accuracy: 0.9942 - digit1_accuracy: 0.9895 - digit2_accuracy: 0.9942 - digit3_accuracy: 0.9860 - digit4_accuracy: 0.9918 - val_loss: 0.7351 - val_digit0_loss: 0.0473 - val_digit1_loss: 0.1400 - val_digit2_loss: 0.2315 - val_digit3_loss: 0.2067 - val_digit4_loss: 0.1096 - val_digit0_accuracy: 0.9500 - val_digit1_accuracy: 0.8000 - val_digit2_accuracy: 0.6625 - val_digit3_accuracy: 0.6875 - val_digit4_accuracy: 0.8750\n",
            "Epoch 14/20\n",
            "27/27 [==============================] - 4s 144ms/step - loss: 0.0768 - digit0_loss: 0.0093 - digit1_loss: 0.0161 - digit2_loss: 0.0163 - digit3_loss: 0.0191 - digit4_loss: 0.0159 - digit0_accuracy: 0.9977 - digit1_accuracy: 0.9837 - digit2_accuracy: 0.9883 - digit3_accuracy: 0.9848 - digit4_accuracy: 0.9907 - val_loss: 0.7936 - val_digit0_loss: 0.0377 - val_digit1_loss: 0.1685 - val_digit2_loss: 0.2314 - val_digit3_loss: 0.2365 - val_digit4_loss: 0.1194 - val_digit0_accuracy: 0.9375 - val_digit1_accuracy: 0.7500 - val_digit2_accuracy: 0.6500 - val_digit3_accuracy: 0.7000 - val_digit4_accuracy: 0.8625\n",
            "Epoch 15/20\n",
            "27/27 [==============================] - 4s 151ms/step - loss: 0.0720 - digit0_loss: 0.0084 - digit1_loss: 0.0128 - digit2_loss: 0.0175 - digit3_loss: 0.0184 - digit4_loss: 0.0149 - digit0_accuracy: 0.9977 - digit1_accuracy: 0.9918 - digit2_accuracy: 0.9907 - digit3_accuracy: 0.9860 - digit4_accuracy: 0.9872 - val_loss: 0.7709 - val_digit0_loss: 0.0418 - val_digit1_loss: 0.1684 - val_digit2_loss: 0.2181 - val_digit3_loss: 0.2295 - val_digit4_loss: 0.1130 - val_digit0_accuracy: 0.9250 - val_digit1_accuracy: 0.7750 - val_digit2_accuracy: 0.6625 - val_digit3_accuracy: 0.6875 - val_digit4_accuracy: 0.8750\n",
            "Epoch 16/20\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 0.0711 - digit0_loss: 0.0103 - digit1_loss: 0.0129 - digit2_loss: 0.0181 - digit3_loss: 0.0163 - digit4_loss: 0.0135 - digit0_accuracy: 0.9907 - digit1_accuracy: 0.9930 - digit2_accuracy: 0.9802 - digit3_accuracy: 0.9860 - digit4_accuracy: 0.9872 - val_loss: 0.7112 - val_digit0_loss: 0.0440 - val_digit1_loss: 0.1605 - val_digit2_loss: 0.2242 - val_digit3_loss: 0.1828 - val_digit4_loss: 0.0996 - val_digit0_accuracy: 0.9625 - val_digit1_accuracy: 0.7625 - val_digit2_accuracy: 0.6500 - val_digit3_accuracy: 0.7000 - val_digit4_accuracy: 0.8500\n",
            "Epoch 17/20\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 0.0739 - digit0_loss: 0.0107 - digit1_loss: 0.0180 - digit2_loss: 0.0174 - digit3_loss: 0.0136 - digit4_loss: 0.0143 - digit0_accuracy: 0.9907 - digit1_accuracy: 0.9814 - digit2_accuracy: 0.9848 - digit3_accuracy: 0.9918 - digit4_accuracy: 0.9907 - val_loss: 0.7332 - val_digit0_loss: 0.0408 - val_digit1_loss: 0.1702 - val_digit2_loss: 0.2227 - val_digit3_loss: 0.2035 - val_digit4_loss: 0.0960 - val_digit0_accuracy: 0.9375 - val_digit1_accuracy: 0.7750 - val_digit2_accuracy: 0.6625 - val_digit3_accuracy: 0.6875 - val_digit4_accuracy: 0.8750\n",
            "Epoch 18/20\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 0.0809 - digit0_loss: 0.0135 - digit1_loss: 0.0170 - digit2_loss: 0.0194 - digit3_loss: 0.0165 - digit4_loss: 0.0145 - digit0_accuracy: 0.9895 - digit1_accuracy: 0.9860 - digit2_accuracy: 0.9825 - digit3_accuracy: 0.9872 - digit4_accuracy: 0.9895 - val_loss: 0.7358 - val_digit0_loss: 0.0407 - val_digit1_loss: 0.1757 - val_digit2_loss: 0.2178 - val_digit3_loss: 0.1963 - val_digit4_loss: 0.1053 - val_digit0_accuracy: 0.9500 - val_digit1_accuracy: 0.7375 - val_digit2_accuracy: 0.7125 - val_digit3_accuracy: 0.6625 - val_digit4_accuracy: 0.8625\n",
            "Epoch 19/20\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 0.0775 - digit0_loss: 0.0127 - digit1_loss: 0.0176 - digit2_loss: 0.0145 - digit3_loss: 0.0193 - digit4_loss: 0.0134 - digit0_accuracy: 0.9907 - digit1_accuracy: 0.9883 - digit2_accuracy: 0.9930 - digit3_accuracy: 0.9872 - digit4_accuracy: 0.9918 - val_loss: 0.7419 - val_digit0_loss: 0.0349 - val_digit1_loss: 0.1579 - val_digit2_loss: 0.2249 - val_digit3_loss: 0.2101 - val_digit4_loss: 0.1141 - val_digit0_accuracy: 0.9500 - val_digit1_accuracy: 0.7375 - val_digit2_accuracy: 0.6375 - val_digit3_accuracy: 0.6625 - val_digit4_accuracy: 0.8875\n",
            "Epoch 20/20\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0756 - digit0_loss: 0.0107 - digit1_loss: 0.0181 - digit2_loss: 0.0156 - digit3_loss: 0.0189 - digit4_loss: 0.0124 - digit0_accuracy: 0.9953 - digit1_accuracy: 0.9837 - digit2_accuracy: 0.9883 - digit3_accuracy: 0.9825 - digit4_accuracy: 0.9930 - val_loss: 0.7496 - val_digit0_loss: 0.0453 - val_digit1_loss: 0.1752 - val_digit2_loss: 0.2269 - val_digit3_loss: 0.2075 - val_digit4_loss: 0.0947 - val_digit0_accuracy: 0.9375 - val_digit1_accuracy: 0.7250 - val_digit2_accuracy: 0.6500 - val_digit3_accuracy: 0.6875 - val_digit4_accuracy: 0.9125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMR4jUER1IXM"
      },
      "source": [
        "# **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZqPvpB7bduw"
      },
      "source": [
        "def transform_data(path):\n",
        "    print ('loading dataset...')\n",
        "    x = []\n",
        "    y=[]\n",
        "    # r=root, d=directories, f = files\n",
        "    counter = 0\n",
        "    for r, d, f in os.walk(path):\n",
        "        for fl in f:\n",
        "            if '.png' in fl:\n",
        "                flr = fl.split('_')[0]\n",
        "                counter += 1\n",
        "                y.append(flr)\n",
        "\n",
        "                img = cv2.imread(os.path.join(r, fl))\n",
        "                #cv2_imshow(img)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                img = cv2.resize(img, (int(135/2), int(50/2)), interpolation=cv2.INTER_AREA)\n",
        "                img = np.reshape(img, (img.shape[0], img.shape[1], 1))\n",
        "                x.append(img)\n",
        "\n",
        "\n",
        "    print('dataset size:', counter)\n",
        "    return np.array(x),y"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1pVX7FDCsIB",
        "outputId": "451c875e-b7e2-49a0-c49b-3db65eb02e3b"
      },
      "source": [
        "NUM_OF_LETTERS=5\n",
        "x,k = transform_data('./electoral-captchas')\n",
        "x = x.astype('float32')"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading dataset...\n",
            "dataset size: 1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEtBhvhIcGn3"
      },
      "source": [
        "y=model.predict(x)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0VuFDTddAXS"
      },
      "source": [
        "y=np.argmax(y, axis=2)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABMi1aqreKy2"
      },
      "source": [
        "l=[]\n",
        "for i in range(y.shape[1]):\n",
        "  num=y[0][i]*10000+y[1][i]*1000+y[2][i]*100+y[3][i]*10+y[4][i]\n",
        "  l.append(num)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdADvVt2eQy0",
        "outputId": "82a55f6c-145e-4a9e-d179-4f0c959aaa67"
      },
      "source": [
        "l"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[72125,\n",
              " 13539,\n",
              " 36677,\n",
              " 98473,\n",
              " 97324,\n",
              " 88419,\n",
              " 73191,\n",
              " 65692,\n",
              " 69562,\n",
              " 44697,\n",
              " 99999,\n",
              " 51415,\n",
              " 88784,\n",
              " 44177,\n",
              " 81567,\n",
              " 74191,\n",
              " 64598,\n",
              " 14461,\n",
              " 41352,\n",
              " 16892,\n",
              " 27591,\n",
              " 27366,\n",
              " 47667,\n",
              " 41123,\n",
              " 72989,\n",
              " 94867,\n",
              " 52883,\n",
              " 27481,\n",
              " 54195,\n",
              " 27763,\n",
              " 15315,\n",
              " 99892,\n",
              " 18878,\n",
              " 97687,\n",
              " 78732,\n",
              " 17598,\n",
              " 38981,\n",
              " 61835,\n",
              " 97613,\n",
              " 41379,\n",
              " 76247,\n",
              " 38624,\n",
              " 22988,\n",
              " 88278,\n",
              " 11575,\n",
              " 42379,\n",
              " 91588,\n",
              " 14762,\n",
              " 54715,\n",
              " 65384,\n",
              " 81152,\n",
              " 14634,\n",
              " 12495,\n",
              " 54255,\n",
              " 78572,\n",
              " 34459,\n",
              " 51282,\n",
              " 28225,\n",
              " 46625,\n",
              " 28275,\n",
              " 22434,\n",
              " 83283,\n",
              " 55574,\n",
              " 96395,\n",
              " 38486,\n",
              " 16373,\n",
              " 54944,\n",
              " 66531,\n",
              " 49823,\n",
              " 66244,\n",
              " 36298,\n",
              " 29439,\n",
              " 96792,\n",
              " 96865,\n",
              " 38544,\n",
              " 73883,\n",
              " 58887,\n",
              " 79575,\n",
              " 24757,\n",
              " 89162,\n",
              " 31936,\n",
              " 79598,\n",
              " 66766,\n",
              " 24758,\n",
              " 22788,\n",
              " 88293,\n",
              " 74196,\n",
              " 87498,\n",
              " 86592,\n",
              " 47793,\n",
              " 84662,\n",
              " 56662,\n",
              " 75687,\n",
              " 65645,\n",
              " 19595,\n",
              " 11425,\n",
              " 97395,\n",
              " 48946,\n",
              " 16911,\n",
              " 95366,\n",
              " 51544,\n",
              " 22115,\n",
              " 33858,\n",
              " 37364,\n",
              " 48975,\n",
              " 38227,\n",
              " 51196,\n",
              " 79526,\n",
              " 76565,\n",
              " 99283,\n",
              " 39742,\n",
              " 85299,\n",
              " 51894,\n",
              " 87894,\n",
              " 55442,\n",
              " 59617,\n",
              " 14599,\n",
              " 97396,\n",
              " 67449,\n",
              " 73739,\n",
              " 59991,\n",
              " 22421,\n",
              " 96973,\n",
              " 23743,\n",
              " 38556,\n",
              " 68624,\n",
              " 55241,\n",
              " 35756,\n",
              " 44719,\n",
              " 54237,\n",
              " 26565,\n",
              " 98766,\n",
              " 12194,\n",
              " 28319,\n",
              " 45341,\n",
              " 18893,\n",
              " 78285,\n",
              " 98755,\n",
              " 42218,\n",
              " 83977,\n",
              " 67591,\n",
              " 99376,\n",
              " 81337,\n",
              " 75185,\n",
              " 16644,\n",
              " 37889,\n",
              " 19732,\n",
              " 96329,\n",
              " 88272,\n",
              " 59883,\n",
              " 42511,\n",
              " 57315,\n",
              " 73237,\n",
              " 72313,\n",
              " 87272,\n",
              " 12595,\n",
              " 19287,\n",
              " 54457,\n",
              " 92642,\n",
              " 26886,\n",
              " 92365,\n",
              " 66591,\n",
              " 64657,\n",
              " 79219,\n",
              " 25998,\n",
              " 97647,\n",
              " 67612,\n",
              " 87559,\n",
              " 52941,\n",
              " 88224,\n",
              " 55254,\n",
              " 72473,\n",
              " 94498,\n",
              " 59986,\n",
              " 47591,\n",
              " 54477,\n",
              " 81227,\n",
              " 32585,\n",
              " 95224,\n",
              " 45958,\n",
              " 87442,\n",
              " 16434,\n",
              " 61345,\n",
              " 47974,\n",
              " 72844,\n",
              " 58957,\n",
              " 89855,\n",
              " 36717,\n",
              " 62117,\n",
              " 96339,\n",
              " 13941,\n",
              " 83275,\n",
              " 94496,\n",
              " 71295,\n",
              " 78473,\n",
              " 23592,\n",
              " 42549,\n",
              " 69323,\n",
              " 27229,\n",
              " 69561,\n",
              " 28485,\n",
              " 59932,\n",
              " 89995,\n",
              " 49285,\n",
              " 59151,\n",
              " 63539,\n",
              " 54314,\n",
              " 19552,\n",
              " 55174,\n",
              " 72565,\n",
              " 43814,\n",
              " 39911,\n",
              " 11167,\n",
              " 62519,\n",
              " 21841,\n",
              " 36732,\n",
              " 93734,\n",
              " 42591,\n",
              " 63327,\n",
              " 89984,\n",
              " 18644,\n",
              " 91562,\n",
              " 52235,\n",
              " 42357,\n",
              " 16957,\n",
              " 69546,\n",
              " 93548,\n",
              " 17579,\n",
              " 49194,\n",
              " 17569,\n",
              " 72825,\n",
              " 22934,\n",
              " 16859,\n",
              " 37399,\n",
              " 71267,\n",
              " 38586,\n",
              " 98975,\n",
              " 45591,\n",
              " 42741,\n",
              " 39644,\n",
              " 62563,\n",
              " 44418,\n",
              " 66991,\n",
              " 75612,\n",
              " 66727,\n",
              " 53297,\n",
              " 92587,\n",
              " 67594,\n",
              " 32522,\n",
              " 97198,\n",
              " 81179,\n",
              " 49919,\n",
              " 15823,\n",
              " 86754,\n",
              " 69741,\n",
              " 57335,\n",
              " 54462,\n",
              " 91472,\n",
              " 96633,\n",
              " 47884,\n",
              " 46691,\n",
              " 85441,\n",
              " 47375,\n",
              " 96997,\n",
              " 29432,\n",
              " 52774,\n",
              " 74176,\n",
              " 35633,\n",
              " 89612,\n",
              " 31362,\n",
              " 82922,\n",
              " 41365,\n",
              " 74254,\n",
              " 43213,\n",
              " 54457,\n",
              " 26219,\n",
              " 45571,\n",
              " 32329,\n",
              " 29741,\n",
              " 44991,\n",
              " 63279,\n",
              " 67498,\n",
              " 46777,\n",
              " 42498,\n",
              " 11522,\n",
              " 47936,\n",
              " 67616,\n",
              " 26415,\n",
              " 39588,\n",
              " 46674,\n",
              " 67692,\n",
              " 83648,\n",
              " 39332,\n",
              " 42871,\n",
              " 38599,\n",
              " 14347,\n",
              " 54667,\n",
              " 88411,\n",
              " 94894,\n",
              " 49593,\n",
              " 63698,\n",
              " 26131,\n",
              " 53323,\n",
              " 88443,\n",
              " 85275,\n",
              " 33894,\n",
              " 76653,\n",
              " 66444,\n",
              " 85555,\n",
              " 89611,\n",
              " 43889,\n",
              " 53149,\n",
              " 74643,\n",
              " 97761,\n",
              " 42619,\n",
              " 21186,\n",
              " 76275,\n",
              " 23178,\n",
              " 16651,\n",
              " 26451,\n",
              " 87188,\n",
              " 79142,\n",
              " 95784,\n",
              " 12329,\n",
              " 51844,\n",
              " 95812,\n",
              " 11815,\n",
              " 74977,\n",
              " 97175,\n",
              " 24356,\n",
              " 81169,\n",
              " 22435,\n",
              " 36752,\n",
              " 44859,\n",
              " 72293,\n",
              " 44175,\n",
              " 49396,\n",
              " 11483,\n",
              " 48225,\n",
              " 78592,\n",
              " 47896,\n",
              " 48746,\n",
              " 86128,\n",
              " 31966,\n",
              " 58135,\n",
              " 81111,\n",
              " 66412,\n",
              " 35757,\n",
              " 14182,\n",
              " 46452,\n",
              " 71415,\n",
              " 96848,\n",
              " 96266,\n",
              " 17319,\n",
              " 91512,\n",
              " 81586,\n",
              " 24746,\n",
              " 66698,\n",
              " 49123,\n",
              " 12666,\n",
              " 35384,\n",
              " 36777,\n",
              " 96781,\n",
              " 78592,\n",
              " 66711,\n",
              " 16972,\n",
              " 76184,\n",
              " 71944,\n",
              " 15599,\n",
              " 14373,\n",
              " 69617,\n",
              " 46195,\n",
              " 46456,\n",
              " 17832,\n",
              " 89597,\n",
              " 63749,\n",
              " 95131,\n",
              " 99842,\n",
              " 28394,\n",
              " 69598,\n",
              " 65549,\n",
              " 65595,\n",
              " 89293,\n",
              " 42496,\n",
              " 78559,\n",
              " 23913,\n",
              " 72618,\n",
              " 55957,\n",
              " 24295,\n",
              " 98979,\n",
              " 71827,\n",
              " 68712,\n",
              " 71592,\n",
              " 66118,\n",
              " 39752,\n",
              " 15741,\n",
              " 27266,\n",
              " 62394,\n",
              " 53455,\n",
              " 68453,\n",
              " 41788,\n",
              " 11644,\n",
              " 25396,\n",
              " 45198,\n",
              " 82519,\n",
              " 21417,\n",
              " 14777,\n",
              " 73428,\n",
              " 48538,\n",
              " 68163,\n",
              " 94741,\n",
              " 76266,\n",
              " 15375,\n",
              " 98961,\n",
              " 99953,\n",
              " 33437,\n",
              " 38579,\n",
              " 61754,\n",
              " 71966,\n",
              " 75347,\n",
              " 49282,\n",
              " 26247,\n",
              " 94592,\n",
              " 79613,\n",
              " 99363,\n",
              " 51839,\n",
              " 95764,\n",
              " 23593,\n",
              " 98655,\n",
              " 85984,\n",
              " 56841,\n",
              " 67893,\n",
              " 62344,\n",
              " 81192,\n",
              " 57465,\n",
              " 48218,\n",
              " 57884,\n",
              " 72219,\n",
              " 87884,\n",
              " 23966,\n",
              " 25142,\n",
              " 76271,\n",
              " 44445,\n",
              " 66961,\n",
              " 96465,\n",
              " 66757,\n",
              " 97748,\n",
              " 38239,\n",
              " 65525,\n",
              " 54496,\n",
              " 89562,\n",
              " 24859,\n",
              " 38755,\n",
              " 13822,\n",
              " 14544,\n",
              " 53278,\n",
              " 37835,\n",
              " 33598,\n",
              " 51545,\n",
              " 34549,\n",
              " 72518,\n",
              " 37155,\n",
              " 66854,\n",
              " 34747,\n",
              " 94516,\n",
              " 88772,\n",
              " 13999,\n",
              " 95762,\n",
              " 17886,\n",
              " 83685,\n",
              " 33938,\n",
              " 94318,\n",
              " 61517,\n",
              " 66891,\n",
              " 55172,\n",
              " 94299,\n",
              " 39117,\n",
              " 24922,\n",
              " 79955,\n",
              " 52698,\n",
              " 46575,\n",
              " 78699,\n",
              " 19479,\n",
              " 39917,\n",
              " 88445,\n",
              " 77514,\n",
              " 84889,\n",
              " 38286,\n",
              " 82821,\n",
              " 58795,\n",
              " 82593,\n",
              " 35668,\n",
              " 18549,\n",
              " 75567,\n",
              " 86926,\n",
              " 61595,\n",
              " 62667,\n",
              " 98318,\n",
              " 42374,\n",
              " 89198,\n",
              " 36965,\n",
              " 67784,\n",
              " 44263,\n",
              " 19374,\n",
              " 89557,\n",
              " 36965,\n",
              " 16934,\n",
              " 33944,\n",
              " 35612,\n",
              " 38271,\n",
              " 97889,\n",
              " 54883,\n",
              " 23957,\n",
              " 38286,\n",
              " 11634,\n",
              " 21394,\n",
              " 49138,\n",
              " 28596,\n",
              " 24537,\n",
              " 47593,\n",
              " 62158,\n",
              " 95587,\n",
              " 18677,\n",
              " 15835,\n",
              " 89947,\n",
              " 19735,\n",
              " 58866,\n",
              " 49228,\n",
              " 63377,\n",
              " 33327,\n",
              " 16889,\n",
              " 77248,\n",
              " 94426,\n",
              " 86319,\n",
              " 75914,\n",
              " 27375,\n",
              " 98251,\n",
              " 15898,\n",
              " 41125,\n",
              " 52415,\n",
              " 46773,\n",
              " 24715,\n",
              " 82469,\n",
              " 57196,\n",
              " 95741,\n",
              " 52524,\n",
              " 92873,\n",
              " 36757,\n",
              " 23953,\n",
              " 19883,\n",
              " 36574,\n",
              " 45677,\n",
              " 16931,\n",
              " 32821,\n",
              " 88565,\n",
              " 41986,\n",
              " 48145,\n",
              " 55881,\n",
              " 32366,\n",
              " 51196,\n",
              " 86114,\n",
              " 58899,\n",
              " 76894,\n",
              " 35766,\n",
              " 85151,\n",
              " 34982,\n",
              " 82989,\n",
              " 94251,\n",
              " 24193,\n",
              " 54869,\n",
              " 25983,\n",
              " 57118,\n",
              " 64472,\n",
              " 41115,\n",
              " 55983,\n",
              " 65238,\n",
              " 63268,\n",
              " 89418,\n",
              " 85657,\n",
              " 48268,\n",
              " 27565,\n",
              " 59169,\n",
              " 65887,\n",
              " 58945,\n",
              " 97154,\n",
              " 25329,\n",
              " 51824,\n",
              " 85379,\n",
              " 53213,\n",
              " 38399,\n",
              " 86779,\n",
              " 17619,\n",
              " 54944,\n",
              " 13767,\n",
              " 64157,\n",
              " 94959,\n",
              " 11786,\n",
              " 79662,\n",
              " 25594,\n",
              " 14797,\n",
              " 97695,\n",
              " 24943,\n",
              " 36651,\n",
              " 49188,\n",
              " 13752,\n",
              " 59775,\n",
              " 63886,\n",
              " 86542,\n",
              " 44485,\n",
              " 86275,\n",
              " 56175,\n",
              " 76565,\n",
              " 24173,\n",
              " 79555,\n",
              " 98449,\n",
              " 19374,\n",
              " 37735,\n",
              " 76518,\n",
              " 71843,\n",
              " 85642,\n",
              " 81578,\n",
              " 59356,\n",
              " 34286,\n",
              " 28388,\n",
              " 91379,\n",
              " 13224,\n",
              " 61865,\n",
              " 62271,\n",
              " 85469,\n",
              " 46717,\n",
              " 58118,\n",
              " 13317,\n",
              " 44197,\n",
              " 36849,\n",
              " 49955,\n",
              " 16936,\n",
              " 97315,\n",
              " 24434,\n",
              " 99752,\n",
              " 93369,\n",
              " 91594,\n",
              " 15984,\n",
              " 27969,\n",
              " 49181,\n",
              " 17493,\n",
              " 75469,\n",
              " 29847,\n",
              " 21765,\n",
              " 96332,\n",
              " 48775,\n",
              " 47986,\n",
              " 97837,\n",
              " 81445,\n",
              " 71996,\n",
              " 11529,\n",
              " 33466,\n",
              " 34342,\n",
              " 99761,\n",
              " 14664,\n",
              " 26258,\n",
              " 37529,\n",
              " 88218,\n",
              " 87668,\n",
              " 87895,\n",
              " 72518,\n",
              " 12453,\n",
              " 42944,\n",
              " 11835,\n",
              " 77268,\n",
              " 32198,\n",
              " 92488,\n",
              " 17567,\n",
              " 89967,\n",
              " 72517,\n",
              " 68826,\n",
              " 45983,\n",
              " 97324,\n",
              " 41121,\n",
              " 67517,\n",
              " 75398,\n",
              " 14869,\n",
              " 67318,\n",
              " 41212,\n",
              " 44573,\n",
              " 79149,\n",
              " 12649,\n",
              " 36967,\n",
              " 99865,\n",
              " 24353,\n",
              " 37347,\n",
              " 26588,\n",
              " 57522,\n",
              " 82595,\n",
              " 63745,\n",
              " 26984,\n",
              " 87858,\n",
              " 58277,\n",
              " 84711,\n",
              " 69995,\n",
              " 49197,\n",
              " 16254,\n",
              " 48448,\n",
              " 12882,\n",
              " 87693,\n",
              " 35518,\n",
              " 63639,\n",
              " 89254,\n",
              " 58855,\n",
              " 56296,\n",
              " 72444,\n",
              " 42195,\n",
              " 34956,\n",
              " 86238,\n",
              " 12821,\n",
              " 78695,\n",
              " 78969,\n",
              " 33171,\n",
              " 97372,\n",
              " 66672,\n",
              " 16282,\n",
              " 41999,\n",
              " 57717,\n",
              " 76989,\n",
              " 61275,\n",
              " 38236,\n",
              " 39919,\n",
              " 45647,\n",
              " 24634,\n",
              " 27658,\n",
              " 49847,\n",
              " 89766,\n",
              " 77916,\n",
              " 33664,\n",
              " 46825,\n",
              " 77224,\n",
              " 75873,\n",
              " 84687,\n",
              " 42422,\n",
              " 14894,\n",
              " 46682,\n",
              " 82649,\n",
              " 26518,\n",
              " 83845,\n",
              " 91489,\n",
              " 51817,\n",
              " 34347,\n",
              " 56155,\n",
              " 33898,\n",
              " 66637,\n",
              " 87896,\n",
              " 77763,\n",
              " 25492,\n",
              " 51818,\n",
              " 73857,\n",
              " 68826,\n",
              " 62225,\n",
              " 28486,\n",
              " 46286,\n",
              " 74169,\n",
              " 48144,\n",
              " 66586,\n",
              " 54158,\n",
              " 15747,\n",
              " 75677,\n",
              " 97866,\n",
              " 42773,\n",
              " 53795,\n",
              " 46675,\n",
              " 89885,\n",
              " 66795,\n",
              " 75459,\n",
              " 95119,\n",
              " 63131,\n",
              " 79244,\n",
              " 76646,\n",
              " 25431,\n",
              " 24187,\n",
              " 68191,\n",
              " 79298,\n",
              " 15234,\n",
              " 34967,\n",
              " 65474,\n",
              " 75983,\n",
              " 37324,\n",
              " 46516,\n",
              " 24359,\n",
              " 13868,\n",
              " 59848,\n",
              " 17899,\n",
              " 24368,\n",
              " 46692,\n",
              " 86413,\n",
              " 96471,\n",
              " 59885,\n",
              " 71555,\n",
              " 22147,\n",
              " 79155,\n",
              " 79169,\n",
              " 96975,\n",
              " 59359,\n",
              " 81784,\n",
              " 75647,\n",
              " 19315,\n",
              " 35678,\n",
              " 65744,\n",
              " 66652,\n",
              " 35714,\n",
              " 47565,\n",
              " 24846,\n",
              " 13756,\n",
              " 52531,\n",
              " 66651,\n",
              " 83213,\n",
              " 44675,\n",
              " 33371,\n",
              " 99519,\n",
              " 38633,\n",
              " 14134,\n",
              " 14193,\n",
              " 98275,\n",
              " 88883,\n",
              " 89998,\n",
              " 46736,\n",
              " 14775,\n",
              " 74148,\n",
              " 73857,\n",
              " 27591,\n",
              " 82779,\n",
              " 59165,\n",
              " 88737,\n",
              " 33762,\n",
              " 65557,\n",
              " 94931,\n",
              " 45162,\n",
              " 65527,\n",
              " 33772,\n",
              " 41375,\n",
              " 87773,\n",
              " 73693,\n",
              " 79559,\n",
              " 18345,\n",
              " 16298,\n",
              " 81885,\n",
              " 74419,\n",
              " 63386,\n",
              " 15578,\n",
              " 97521,\n",
              " 28195,\n",
              " 88687,\n",
              " 13284,\n",
              " 31576,\n",
              " 86828,\n",
              " 55847,\n",
              " 72246,\n",
              " 39727,\n",
              " 62611,\n",
              " 74684,\n",
              " 75833,\n",
              " 84419,\n",
              " 16146,\n",
              " 88445,\n",
              " 99794,\n",
              " 39314,\n",
              " 72824,\n",
              " 52746,\n",
              " 85595,\n",
              " 71941,\n",
              " 27486,\n",
              " 56511,\n",
              " 27554,\n",
              " 16989,\n",
              " 44562,\n",
              " 81327,\n",
              " 79881,\n",
              " 75845,\n",
              " 96799,\n",
              " 12338,\n",
              " 48528,\n",
              " 12972,\n",
              " 81288,\n",
              " 46971,\n",
              " 27522,\n",
              " 13296,\n",
              " 94448,\n",
              " 49997,\n",
              " 48727,\n",
              " 49648,\n",
              " 64861,\n",
              " 54867,\n",
              " 31392,\n",
              " 36415,\n",
              " 38449,\n",
              " 15289,\n",
              " 75873,\n",
              " 42158,\n",
              " 99839,\n",
              " 76266,\n",
              " 32812,\n",
              " 37149,\n",
              " 45471,\n",
              " 63588,\n",
              " 47694,\n",
              " 58143,\n",
              " 66575,\n",
              " 23746,\n",
              " 35395,\n",
              " 91174,\n",
              " 64174,\n",
              " 35985,\n",
              " 36859,\n",
              " 21846,\n",
              " 11114,\n",
              " 97731,\n",
              " 84199,\n",
              " 96264,\n",
              " 46493,\n",
              " 18773,\n",
              " 51271,\n",
              " 75642,\n",
              " 15634,\n",
              " 53236,\n",
              " 91562,\n",
              " 38598,\n",
              " 25351,\n",
              " 57357,\n",
              " 51293,\n",
              " 94826,\n",
              " 36531,\n",
              " 79843,\n",
              " 33376,\n",
              " 33412,\n",
              " 59219,\n",
              " 43269,\n",
              " 61115,\n",
              " 63695,\n",
              " 67326,\n",
              " 31336,\n",
              " 95384,\n",
              " 54512,\n",
              " 88796,\n",
              " 12941,\n",
              " 13788,\n",
              " 82927,\n",
              " 22288,\n",
              " 13598,\n",
              " 28394,\n",
              " 82711,\n",
              " 41878,\n",
              " 79656,\n",
              " 73317,\n",
              " 63881,\n",
              " 55212,\n",
              " 43488,\n",
              " 18691,\n",
              " 13514,\n",
              " 38582,\n",
              " 74549,\n",
              " 66843,\n",
              " 87776,\n",
              " 89685,\n",
              " 12351,\n",
              " 87836,\n",
              " 36943,\n",
              " 19219,\n",
              " 67517,\n",
              " 93649,\n",
              " 49677,\n",
              " 57191,\n",
              " 86786,\n",
              " 45998,\n",
              " 42197,\n",
              " 71368,\n",
              " 31342,\n",
              " 95667,\n",
              " 34736,\n",
              " 63657,\n",
              " 84222,\n",
              " 35177,\n",
              " 89325,\n",
              " 71285,\n",
              " 99849,\n",
              " 83824,\n",
              " 91826,\n",
              " 24587,\n",
              " 88523,\n",
              " 99228,\n",
              " 91588,\n",
              " 74885,\n",
              " 94888,\n",
              " 87869,\n",
              " 46776,\n",
              " 91594,\n",
              " 56212,\n",
              " 31956,\n",
              " 34331,\n",
              " 71146,\n",
              " 87744,\n",
              " 59283,\n",
              " 69189,\n",
              " 47989,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQsCyPJQgS-9"
      },
      "source": [
        "df = pd.DataFrame({\"image_name\" : k, \"Number\" : l})\n",
        "df.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S6LyWnu4yNg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}